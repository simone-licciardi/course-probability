% 99_exercises.tex
%! TeX root = ../main.tex

\chapter*{Bassetti Unbound}
\addcontentsline{toc}{chapter}{Exercises}

\begin{my_ex}
	Let $\Omega$ be a set and let $A \subset \Omega$ a subset from it. Then, show that $\{ A, A^\mathsf{c}, \emptyset, \Omega \}$ is a $\sigma$-algebra.
\end{my_ex}
\begin{my_notes}
	This is the easiest nontrivial $\sigma$-algebra. It models a bet: the event may either happen or not (or nor could happen, that is the same as all the outcomes being realized). (??)
\end{my_notes}

\begin{my_ex}
	Let $\{ \mathcal{F}_\alpha \}_{\alpha \in I}$ be a colletion of $\sigma$-algebras. Is $\bigcap_{\alpha \in I} \mathcal{F}_\alpha$ a $\sigma$-algebra. What about $\bigcup_{\alpha \in I} \mathcal{F}_\alpha$?
\end{my_ex}
\begin{my_notes}
	This\footnote{The answer is that the first is, in fact, a $\sigma$-algebra, while the second not so, as it does not contain crossed unions and intersections.} justifies minimality arguments on the function $\sigma(\cdot)$. Read this \href{https://math.stackexchange.com/questions/54172/the-sigma-algebra-of-subsets-of-x-generated-by-a-set-mathcala-is-the-s/}{masterpiece}, this \href{https://groups.google.com/g/sci.math/c/DjVj6RiXOLs/m/PSMsTtfEnO8J}{essay} and this very general and technical \href{https://ncatlab.org/nlab/show/Moore+closure}{site} .
\end{my_notes}

\begin{my_ex}
	Prove the well-definiteness of $\sigma(\mathcal{E})$ as the minimal $\sigma$-algebra containing $\mathcal{E}$.
\end{my_ex}
\begin{my_notes}[Sketch of proof]
	Let $\Sigma(\mathcal{E})$ be the collection of all the $\sigma$-algebras containing the collection $\mathcal{E}$ of subsets of $\Omega$. (Prove that) $\Sigma(\mathcal{E})$ is not empty, and the family intersects to $\bigcap_{S\in\mathcal{E}}S = \sigma(\mathcal{E})$.
\end{my_notes}

\begin{my_ex}
	Let $E_1$,$E_2$ be events of $\Omega$. Think of a sample space and construct a measure of probability $\mathbb{P} : \mathcal{P}(\Omega) \to \mathbb{R}$ such that the two events are independent and $\mathbb{P}(E_1)=\mathbb{P}(E_2)=\frac{1}{2}$.
\end{my_ex}
\begin{my_notes}
	(??) % tip was to use uniform probability 
\end{my_notes}

\begin{my_ex}
	Let $\Omega=\mathbb{N}$. Show that $\mathrm{p}(\{n\})=\theta^n(1-\theta)$ for all $n\in\mathbb{N}$ is a discrete probability density. That is, show that it is coherent enough for a probability extending it to $\mathcal{P}(\mathbb{N})$ to exist.  
\end{my_ex}
\begin{my_notes}
	(??)
\end{my_notes}

\begin{my_ex}
	Let $E_1$,$E_2$ be independent events on $\Omega$ such that $\mathrm{p}(E_1)=\mathrm{p}(E_2)=\frac{1}{2}$. Determine the $sigma$-algebra, and find the probability $\mathbb{P}$ on this space consistent with the two values of $\mathrm{p}$.
\end{my_ex}
\begin{my_ex}
	% esercizio finale esercitazione 12 / 3
\end{my_ex}
\begin{my_remark}
	These are some examples of probability modelization Note that $\Omega$ is basically irrelevant. Here independence, a property \textit{of the probability}\footnote{Independence and conditioal probabilities are the charachteristic that really distinguish a probability from a measure.}, furnishes the necessary information for $\mathbb{P}$ to be defined uniquely. It allows us to work in a context of minimal information, by relating different partitions (that is, states).
\end{my_remark}

\begin{my_ex}[Jacod Protter, 7.1]
	\label{ex_jp_7_1}
	
\end{my_ex}
\begin{my_remark}
	The idea is that only finitely many disjoint events can have probability $\mathbb{P}(E) \leq \alpha$. That is all infinite sequences (convergent or divergent doesn't really matter, as we can restrict ourselves to the $\lim \sup$) need to tend to zero.
\end{my_remark}

\begin{my_ex}[Jacod Protter, 7.2]
	
\end{my_ex}
\begin{my_remark}
	\label{ex_jp_7_2}
	Same idea as in \ref{ex_jp_7_1}, but the fact that here we also apply results about cardinality. That is we group events by having a probability larger than $\frac{1}{n}$ and then use 7.1 to show that their cardinality need be discrete, as the whole collection is countable union of finite collections.
\end{my_remark}

\begin{my_ex}[Jacod Protter, 7.10]
	
\end{my_ex}
\begin{my_remark}
	This is an analytical result, but shows that the definition of discrete random variables is coherent with its charachterization in terms of cumulative density function. 
	
	To prove the result, one could create a bijection between $\mathbb{N}$ and the set of jump discontinuities $\mathbb{D}$, by using monotonicity and order on reals.
	A more instructive approach, though, is that of \ref{ex_jp_7_2}. We consider for each $n$ the set
	\[ 
		D_n = 
		\left\{
			x_0 \in [0,1] : 
			\text{ in } x_0 \text{ is located a jump discontinuity larger than } 
			\frac{1}{n}
		\right\}.
	\]
	By boundedness of $[0,1]$, $D_n$ need be finite. Then, $\bigcup_{n\in\mathbb{N}} D_n$ is discrete. 
	
	Analyitically, you could also show that removable discontinuities need be discrete. See \href{run:assets/removable_disc.pdf}{here} for further considerations. This does not have direct applications in probability.
	% ISSUE WITH HREF^
\end{my_remark}