% 01_complements.tex
%! TeX root = ../main.tex

\chapter*{Complements to Chapter 1}
\addcontentsline{toc}{chapter}{Complements}
% \begin{document}
\section{Probability construction}

Operatively, there are two ways of furnishing a (measure of) probability on a measurable space \measurablespace: we provide \textit{a priori} the complete description of it, or we deduct it from the information we have. That is, key difference is how much information about the probability we are starting with. The first is common in applications such as Bayesian Statistics, where you make an hypothesis on the distribution and then update it with experiments, while the second is recurrent in modelisation. 

In both cases some check are in order, as we need to ensure that the information we have is \textit{coherent}, that is there is a probability which fits the given description, and \textit{sufficient} to uniquely charachterize the probability.

We start with the complitely resolved case of discrete partitions, then move to theoretical results on general settings, and finally deal with the practical aspects of the matter. 

\subsection{Discrete setting}

The case of discrete partitions of the sample space $\Omega$ is complitely resolved: that is we know everything about it with the bare minimal information. We state the theorems that allow and describe this kind of reasoning.

\begin{my_remark}
	\label{usefullness_partitions}
	The reason why we care about partitions is that they model experiments where, at the end, only one of some states of the system is true. 
	Think of rolling 4 dices, and being interested in the results of the first only. Then, only (and exactly) one the \textit{states} "the first dice rolled to $n$" can suceed!
	Formally, that is equivalent to observing that even though $\omega \in \Omega$ describes the 4 results of the 4 rolls, that is it contains information we don't really care about (the other 3 rolls), we can partition the set according to the first result only. 
	Importantly, the remaining structure of $\Omega$ is \textit{not} garbage: for example, partitioning for the first roll could just be the first part of answering "how likely is it that the second dice rolls to 3, given the first rolled to 1?".
\end{my_remark}

\begin{my_theorem}[Existence and Uniqueness]
	\label{disc_partition}
	Let $\dispart$ be a discrete\footnote{That is, it is at most countable: $I \subset \mathbb{N}$} partition of $\Omega$ and suppose that the function $\p:E_k \in \mathcal{E} \to p_k \in \mathbb{R}$ satisfies
	\begin{subnumcases}{}
		\sum_{k\in I} p_k=1 \label{normalization}
		\\
		p_k\geq0 \quad\textit{for all } k \in I.\label{positiveness}
	\end{subnumcases}
	Then, there exist a unique probability $\mathbb{P}$ on $\sigma(\mathcal{E})$ such that $\mathbb{P}$ and $\p$ agree on $\mathcal{E}$. A function $\p$ with the properties (\ref{normalization}) and (\ref{positiveness}) of is called a discrete probability density.
\end{my_theorem}

Morally, if the probability $p_k$ of the events of a discrete partition is known, we are guaranteed that there is a unique probability extending them with consistency to the generated $\sigma$-algebra. 

In this setting, some very operative results are also available: we can describe explicitly each event $E\in\sigma(\mathcal{E})$ and its probability $\mathbb{P}(E)$.
\goodbreak\begin{my_lemma}
	\label{explicit_char1}
	Let $\dispart$ be a discrete partition of $\Omega$. Then,
	\[
		\sigma( \mathcal{E} ) = \left\{ \, \bigcup_{k \in J} E_k \, \text{ for }J \subset I \right\}.
	\]
\end{my_lemma}
\begin{my_lemma}
	\label{explicit_char2}
	Let $\p : E_k \in \mathcal{E} \to p_k \in \mathbb{R}$ and $\mathbb{P} : \sigma(\mathcal{E}) \to \mathbb{R}$ be as is Theorem \ref{disc_partition}. Then,
	\[
		\mathbb{P} \left( \, \bigcup_{k \in J} E_k \,\right) = \sum_{k \in J} \p_k \quad \text{ for all }J \subset I.
	\]
\end{my_lemma}
% commento sul fatto che la chiave della semplicità della sigma algebra sulla partizione è che in non si considerano gli insiemi complementari da nessuna parte: questo semplifica molto i risultati visto che l'unione (o, quindi, l'intersezione) diventa del tutto sufficiente, DA SOLA, a descrivere la collezione! non solo, ma proprio il fatto che non dobbiamo aggiungere set dalla complementazione è ciò che ci permette di trovare le probabilità generiche, visto che trasforma la sigma additività da condizione di coerenza, a formale descrizione della collezione!
\begin{my_remark}
	A special case worth mentioning is that of the atomic partition on a discrete $\Omega$. 
	Here, the $\sigma$-algebra generated is $\mathcal{P}(\Omega)$ and the discrete probability density is commonly referred to as $p(\{ \omega \})=p_\omega$. 
	By the precedent results, $p$ defines a unique probability $\mathbb{P}$ consistent over $\mathcal{E}$ such that
	\begin{equation}
		\mathbb{P} \left( E \right) = \sum_{\omega \in E} p_\omega \quad \text{ for all }E \subset \Omega.		
	\end{equation}
\end{my_remark}
% esempio è la probabilità uniforme, che per essere definita ha bisogno di addirittura uno spazio finito. In queste condizione, se la partizione è atomica e l'evento della partizione (l'atomo) ha prob uguale per ogni atomo, allora parliamo di prob uniforme. in questo caso, si ha che P(E)=#E/#\Omega
Now, we want to show by examples that $\mathbb{P}$ need not be given over just a single partition. Actually, since a probability is a very special kind of measure, it is not even necessary that the information is about its values! We will explain the matter thorugh examples, but first we state an handy result.
\begin{my_corollary}
	\label{cond_partitions}
	Let $\mathcal{E}=\{ E_k \}_{k\in I}$ be a partition of $\Omega$ and suppose that the function $\p:E_k \in \mathcal{E} \to p_k \in \mathbb{R}$ satisfies $\sum_{k\in I} p_k=1$ and $p_k\geq0$ for all $k \in I$. Moreover, let $\mathcal{F}=\{ F_h \}_{h\in J}$ be another partition and suppose for all $k$ such that $p_k > 0$ the function $q^{(k)}:F_h \in \mathcal{F} \to q_{h\,|k} \in \mathbb{R}$ satisfies $\sum_{h \in J} q_{h\,|k}=1$ and $q_{h\,|k}\geq0$ for all $h \in J$.

	Then, there exist a unique probability $\mathbb{P}$ on $\sigma(\mathcal{E}\cup\mathcal{F})$ such that $\mathbb{P}$ and $\p$ agree on $\mathcal{E}$ and
	\[
		\mathbb{P}\left( F_h | E_k \right) = q_{h|k} \quad \text{for all } k \in I \text{ and } h \in J.
	\]
\end{my_corollary}
The result benefits some explaining. 
\begin{my_remark}
	\label{real_part}
	The difference with Theorem \ref{disc_partition} is that the $\sigma$-algebra is \textit{quite bigger}. To understands \textit{how much}, it is sufficient to observe that it can also be charachterized as the $\sigma$-algebra generated by the partition $\mathcal{Q}=\{ E_k \cap F_h\}_{k\in I,h\in J}$ of $\Omega$. 
\end{my_remark}	
\begin{my_remark}
	\label{usefull_condpart}
	Recall Remark \ref{usefullness_partitions}. In proability, it is quite common to study the relationships between different states and this result guarantees that if we were given not only the probability of a state, but also the probability of another state \textit{in relation with} the first, then we can furnish consistently and uniquely the probability over combinations of all sorts of these states.
\end{my_remark}
A useful representation is that of a tree of events. Let us present it with an example.
\begin{my_example}
	(??)% example of usage of this result
	(??)% tree image
\end{my_example}
\begin{my_remark}
	By the precedent Remark, you understand that a special relationship correlating states is that of independence. In that case, we can do one of two things depending on the request of the problem. First, we can use the definition: that is we put $\mathbb{P}(F_h \cap E_k)=\mathbb{P}(F_h)\mathbb{P}(E_k)$, find the probabilities on the partition in Remark \ref{real_part} and then, apply Theorem \ref{disc_partition} and Lemmas \ref{explicit_char1},\ref{explicit_char2} to find $\mathbb{P}$. Second, we make use of the fact that for $\mathbb{P}(E_k)>0$ independence is equivalent to $\mathbb{P}(F_h|E_k)=\mathbb{P}(F_h)$. We establish all the conditional probabilities, and then apply Theorem \ref{cond_partitions} to show the existence of $\mathbb{P}$. Finding the values of $\mathbb{P}$ is then a matter of manipulating conditional probabilities.
\end{my_remark}
\begin{my_example}
	(??) % show way 1
	(??) % show way 2
\end{my_example}
Moreover, this theorem allows us to easy the question of probability modelisation for repeated experiments. 
(??) % esercitazione di prov del 12 /3, discorso di greg su quando dire che le prob delle entries sono aleatorie, allora anche il vettore esito lo è.

And now a final Remark on \textit{why} the discrete partition setting is solvable. 
\begin{my_remark}
	For the "partition" part, it all boils down to the fact that we only consider unions: the complementation is just the union of the other elements, and the intersection is the union of partition elements that are in all the sets. 
	If now you add the "discrete" part, we not only describe everything as unions, but as at most countable unions: that is, complementation will be always well defined. 
	Technically, if we considered an uncountable partition, even if $S$ was a countable union of some of its elements, then the complementary $S^\mathsf{c}$ would be an uncountable union. That is because an uncountable collection without countably many elements is still uncountable. That would make $S^\mathsf{c}$ untractable under \ref{explicit_char2}!
\end{my_remark}

\subsection{Carathéodory Theorem}

For more general settings the short message is that Theorem \ref{disc_partition} holds, provided some conditions, while no explicit characterization like that of Lemmas \ref{explicit_char1},\ref{explicit_char2} is possible.

We present a powerful theorem of measure theory, that does just that. It will allow us to extend a \textit{pre-measure}, a function with some coherence that is defined on a collection smaller than a $\sigma$-algebra, to a probability, in a unique fashion.

\goodbreak\begin{my_definition}
	\label{proprob}
	Let $\alg$ be an algebra defined on $\Omega$. Then, $\preprob:\alg\to\mathbb{R}$ is a \textit{pre-measure} if
	\begin{enumerate}
		\item $\preprob( \Omega ) = 1$ \hfill (Normalization)
		\item $\preprob \left( \, \bigcup^n_{i=1} A_i \, \right) = \sum^n_i \preprob(A_i)$ for $A_i\in\alg$ \hfill (Additivity)
		\item if $\bigcup_{ i \in \mathbb{N} } A_i \in \alg$, then $\preprob \left( \,\bigcup_{ i \in \mathbb{N} } A_i \,\right) = \sum_{ i \in \mathbb{N}} \preprob(A_i)$.
	\end{enumerate}
\end{my_definition}
\begin{my_remark}
	The latter is the condition that ensure coherence with respect to the probability, and can be read as a \textit{need-based \sigmaadd}.
\end{my_remark}

\goodbreak\begin{my_theorem}[Carathéodory's Theorem]
	\label{carathéorodory}
	Let $\alg$ be an algebra defined on $\Omega$, and suppose that $\preprob : \alg \to \mathbb{R}$ is a pre-measure.	Then, there exists a unique probability $\mathbb{P}: \sigma ( \alg ) \to \mathbb{R}$ such that $\preprob$ and $\mathbb{P}$ agree on $\alg$.
\end{my_theorem}
\begin{my_remark}
	This version of the Carathéodory's Theorem is of theoretical interest and provides two results.
	First, it shows that \textbf{existence} of a consistent extension is guaranteed just by requiring the coherence of $\preprob$ with the conditions that the define a probability: these are encoded in Definition \ref{proprob}.
	Moreover, the theorem quantifies the idea that if $\preprob$, the information provided about $\mathbb{P}$ that is, is defined on a large enough collection, then its extension is \textbf{unique}. 
	In particular, we require $\mathbb{P}$ to be given on an algebra, a much smaller collection than a $\sigma$-algebra.
\end{my_remark}

We can refine the result for practical purposes by exploiting the equivalence between $\sigma$-additivity and continuity\footnote{This result from measure theory is taken to be known and the details are out of the scope of these notes.}. 
Better: we aim at simplifing the checks on $\preprob$ rather than changing the statement of \ref{carathéorodory} and we do so by furnishing an equivalent set of conditions.
\goodbreak\begin{my_lemma}[Pre-measure, Continuity characterization]
	Let $\alg$ be an algebra defined on $\Omega$. Then $\preprob:\alg\to\mathbb{R}$ is a pre-measure if and only if
	\begin{enumerate}
		\item $\preprob(\Omega)=1$,
		\item $\preprob \left( \, \bigcup^n_{i=1} A_i \, \right) = \sum^n_i \preprob(A_i)$,
		\item if $A_i \, \big \downarrow \, \emptyset$, then $\preprob(A_i) \big \downarrow0$,
	\end{enumerate}
	where $A_n\in\alg$.
\end{my_lemma}
\begin{my_remark}
	The usefulness of this is that monotone continuity, that is showing a limit is $0$, is generally much easier than working on countable unions to arbitrary sets.
\end{my_remark}

\subsection{Practical construction, set structure}

The following two resources cover the topic well (and probably better than I can).
\begin{itemize}
	\item $\pi$-$\lambda$ Theorem and Monotone Class Theorem: \href{https://almostsuremath.com/2019/10/06/the-monotone-class-theorem/}{link}
	\item Practical construction: Read the "extension.pdf" file in "assets" directory. In particular, recall continuity charchterization.
\end{itemize}
I will leave some operative remarks that integrate the resources, in the rest of the chapter.


% An algebra is still a sizeable class, making it hard to define $\mathbb{P}$. This is what Dynkin’s $\lambda-\pi$ Theorem was designed to simplify.

\begin{my_definition}[$\pi$-system]
	Given a set $\Omega$, a collection of subsets $\mathcal{C}$ is a $\pi$-system if stable it is under finite intersection. Explicitly, if $A_1, \dots, A_n \in \mathcal{C}$ implies that $\bigcap^n_{i=1} A_i \in \mathcal{C}$.
\end{my_definition}
\begin{my_remark}
	Operatively, it suffices to show that $A \cap B \in \mathcal{C}$ whenever $A,B \in \mathcal{C}$, for $\mathcal{C}$ to be a $\pi$-system by inductive argument.
\end{my_remark}
\begin{my_definition}[$\lambda$-system]
	Given a set $\Omega$, a collection of subsets $\mathcal{C}$ containing $\Omega$ is a $\lambda$-system if it is stable under (pairwise) disjoint countable union and complementation. Explicitly, if $A_1, A_2, \dots \in \mathcal{C}$ and $A_i \cap A_j = \emptyset$ for all $i$,$j$ implies that $\bigcup_{i=1} A_i \in \mathcal{C}$ and if .
\end{my_definition}
\begin{my_remark}
	\label{proper_diff_stab}
	Some textbooks require proper difference stability, that is $A,B \in \mathcal{C}$ implies $A \setminus B \in \mathcal{C}$, instead of complementation.
	
	We show that they are equivalent. The question boils down to the identity
	\begin{equation}
		\label{setdiff_compl_eq}
		A \setminus B = A \cap B^\mathsf{C},		
	\end{equation}
	where complementation is taken with respect to a space containing both A and B. 
	
	Since $B \subset A$ the above equation yields that $B \setminus A$ is the complementation of $B$ with respect to $A$, then $\mathcal{C}$ being closed under proper difference is the same as $\mathcal{G}_A=\left \{B \in \mathcal{C} : B \subset A \right \}$, the collection of subsets of $A$ in $\mathcal{C}$, being closed under complementation for all $A \in \mathcal{C}$.	Importantly, this implies complementation stability with respect to $\Omega$.
	
	The converse, that complementation implies proper difference, holds as well. Suppose $B \subset A$. Then, $A \setminus B = A \cap B^\mathsf{C} = (A^\mathsf{C} \cup B)^\mathsf{C} \in \mathcal{C}$ by (\ref{setdiff_compl_eq}) and countable disjoint union.
\end{my_remark}
% \begin{my_remark}
% 	Let us highlight the difference between a $\lambda$-system and a $\sigma$-algebra: in the former the countale unions need to be \textit{disjoint}, while in the latter not so. An example of collection that is closed under disjoint union, but not union, is
% 	\[
% 		\mathcal{C}=\left \{ \emptyset, \{a,b\},\{c,d\},\{a,c\},\{b,d\}, \{a,b,c,d\} \right \}
% 	\]
% \end{my_remark}
% Let us investigate the relationship between a $\sigma$-algebra and these simpler systems. 
% \begin{my_lemma}
% 	A collection is a $\sigma$-algebra if and only if it is both a $\pi$-system and a $\lambda$-system.	
% \end{my_lemma}
% This is a much stronger relation than it looks, as the following theorem shows.
% \begin{my_theorem}[$\lambda-\pi$ Theorem]
% 	\label{lambda-pi}
% 	If $\mathcal{C}$ is a $\pi$-system and $\mathcal{D}$ is a $\lambda$-system containing it, then $\sigma(\mathcal{C}) \subset \mathcal{D}$.
% \end{my_theorem}
% \begin{my_remark}
% 	An equivalent statement would be that $\sigma(\mathcal{C}) = \lambda(\mathcal{C})$, where the latter is the smallest $\lambda$-system generated by $\mathcal{C}_\pi$. That this is unique follows from the intersection of $\lambda$-systems being a $\lambda$-system, that this exist from $\sigma{\mathcal{C}}$ being a $\lambda$-system.
% \end{my_remark} 
% % omitting the fact that this and the following theorem are also criterions that can be used to prove theoretical results. given a class, we show that it is a d-system, and a pi-sysyen instead of a sigma-algebra, which may be easier. the same goes for an algebra+ montone class.
% A similar result to \ref{lambda-pi} is the following, where we weaken the requirements on $\mathcal{D}$ so that it is only required to be a monotone class, at the expense of stronger stability for $\mathcal{C}$.
% \begin{my_theorem}[Monotone Class Theorem, set version]
% 	\label{mct}
% 	If $\mathcal{A}$ is an algebra and $\mathcal{M}$ is a monotone class containing it, then $\sigma(\mathcal{A}) \in \mathcal{M}$.	
% \end{my_theorem}
% \begin{my_remark}
% 	Here, an equivalent statement would be that $ \sigma \left( \mathcal{A} \right) = \mathrm{M} \left( \mathcal{A} \right) $, where the latter is the smallest monotone system generated by $\mathcal{A}$ and existence and uniquess are as above.
% \end{my_remark}
\begin{my_remark}
	The Monotone Class Theorem furnishes a tool to show that a certain property is satisfied by all sets in a $\sigma$-algebra. It is sufficient to show that the $\pi$-system generating the $\sigma$-algebra satisfies it, and that the set satysfing it is a $\lambda$-system. We can show the same if the property is satisfied over an algebra and the class satisfying the property constitues a monotone class. This patter of reasoning is termed a \textit{monotone class argument}.
\end{my_remark}
% % example here would fit well.
% The following is an immediate application of Theorem \ref{carathéorodory} or \ref{mct} equivalently.
% \begin{my_lemma}
% 	Let $\mathbb{P}_1$ and $\mathbb{P}_2$ be probabilities on $\sigma(\mathcal{C})$ and $\mathcal{C}$ be a $\pi$-system. If $\mathbb{P}_1$ and $\mathbb{P}_2$ agree on $\mathcal{C}$, then they agree on $\sigma(\mathcal{C})$.
% \end{my_lemma}
% \begin{my_remark}
% 	The lemma is of practical interest. Evidently, it allows easier comparison between probabilities, as it suffices to check equality on a much smaller collection than the domain. Importantly, the lemma also furnishes sharp\footnote{Mathematical gibberish for ``minimal''} conditions for uniqueness in Theorem \ref{carathéorodory}: it allows us to define the pre-measure on just a $\pi$-system containing $\Omega$, and deduce from that its unique extension.
% \end{my_remark}

% \subsection{Practical construction of probability}

% This continues the precedent section, where we have shown how to divide the construction of the sigma algebra into its components. Now we  set as objective that of showing the passages of the most common practice in probability construction: that of defining the pre-measure on a $\pi$-system, extending it to a semi-algebra, and then to an algebra in order to apply Carathéodory. That of going from the $\pi$-system to the algebra operatively. 

% \href{http://theanalysisofdata.com/probability/E_3.html}{here}.

% \section*{Borel's $\sigma$-algebra}
% \section*{$\sigma$-algebra on Bernoulli Space}
